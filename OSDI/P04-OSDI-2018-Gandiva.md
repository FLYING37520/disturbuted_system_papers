# Title

Gandiva: Introspective Cluster Scheduling for Deep Learning

## Citing

Xiao W, Bhardwaj R, Ramjee R, et al. Gandiva: Introspective cluster scheduling for deep learning[C]//13th {USENIX} Symposium on Operating Systems Design and Implementation ({OSDI} 18). 2018: 595-610.

## Brief Introduction

当前深度学习的调度存在若干问题，由于深度学习作业的执行过程是一种基于反馈式驱动的探索，job开始时以多种配置执行，通过超参数搜索决定作业后续的运行情况，传统静态调度方法依次调度不同的job，并不支持多作业的情况，恰当配置难以被发现，阻塞问题频出，限制资源使用效率的提升；此外DL作业本身也存在工作负载异构性的问题，其敏感资源特征也不一致。为了解决DL调度的高延迟和低效率的问题，提出Gandiva框架，实现任务类型细粒度感知、多种优化手段综合使用的方式来提升DL执行效率。

## Key Methodology

1. 基于数据分析的DL作业执行的可预测性,对深度学习的特征（CPU、GPU工作状态）进行建模学习：
（1）单一作业：服务器内部对作业的具有一定的敏感性，不同CPU核之间、相同CPU核不同GPU之间、同样GPU分布在不同的机器之间，相同成本下其数据本地性和处理速度的差异很大；
（2）作业间干扰：在同样的基础设施下，无论是单个GPU还是多个GPU，随着任务数量的增长，LM作业之间、LM与GNMT之间存在一定程度的性能干扰，ResNet-50、 InceptionV3、DeepSpeech不同数据集的干扰效果不一样；
（3）DL作业内部存在可预测性：不同数据集其差异较大，77倍-3倍不等，但是都有明显的周期性，这是由于 mini-batch progress导致的。

2. DL作业画像驱动的调度，若干种基本的调度手段（更多的类似于操作系统的基本调度问题），防止作业排他性独占GPU：
（1）挂起恢复和装箱：在GPU显存使用低谷挂起对应的DL作业，当所有Job的GPU需求总量不超过GPU核数时，可以将多个任务部署在一个GPU之上，从而提升资源效率；
（2）通过预热方式进行迁移：通过检查点+CIRU的方式进行迁移，降低迁移开销，提升数据本地性；
（3）DL画像：如果用户同意开启，通过不断的资源监控验证装箱是否有效

3. 两种基本的调度策略：
（1）响应式模式：较为基础的模式，提供基于亲和性和提升数据本地性的节点选择策略，只保证快速的分配GPU，从而可以更好的得到autoML的反馈信息；
（2）洞察模式：装箱、迁移、资源动态伸缩、时间片切分等高级策略可选，通过各种途径达到多目标的优化问题。

4. 改造方法：
直接改造原有框架
（1）pytorch：提供时间片切分功能；
（2）TensorFlow：提供迁移功能。

## Data Sets

全部基于已有开源数据集和流行算法，表1和表2.

## Experimental Design

1. 小样本测试：验证时间片切分、装箱、动态资源分配和迁移的有效性；
2. 多作业环境（AutoML）测试：验证多种配置在相同时间下的查找速度，以及集群的资源利用率；
3. 集群环境下测试：时间分片和装箱的效果；
4. 基于真实轨迹进行的模拟测试：轨迹到来模拟；作业完成时间对比。

## Conclusion and Future Work

粗略的想法：
1. DL的特征建模粒度仍然较粗，从数据集、到周期性能不能有更细粒度的刻画方式，周期性是否有更为明晰的表达；
2. 其基本调度策略仍然是传统基于队列的方式，具有一定的局限性，采用bottom-up、强化学习reward等方式是否可以显著改善其性能；
3. 现在仍然是基于GPU整数核、较长的时间分片提升GPU效率，能否有类似于CPU的调度方式和低成本的中断挂起成本；
4. 是否存在各类资源协同调度的问题，提出新的编程API，从而不需要较为困难的DL建模。 
5. 文中提到在显存利用最少的时刻进行suspend并切换，从而减少GPU到CPU拷贝数据大小。但是当时间片结束时，可能需要等待每个任务的mini-batch结束，文中认为这个overhead是可以接受的，相比于要拷贝GPU的大量数据，但是否可以动态控制时间片的长度使得大多数任务能够在相近时刻执行完最近的mini-batch，从而减少overhead？