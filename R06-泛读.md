# 参考文献

//基于贝叶斯优化方法，以深度学习训练作业的数据并行形式为基础，预测需要的AWS实例类型和实例数量
@inproceedings{yi2020not,
  title={Not All Explorations Are Equal: Harnessing Heterogeneous Profiling Cost for Efficient MLaaS Training},
  author={Yi, Jun and Zhang, Chengliang and Wang, Wei and Li, Cheng and Yan, Feng},
  booktitle={2020 IEEE International Parallel and Distributed Processing Symposium (IPDPS)},
  pages={419--428},
  year={2020},
  organization={IEEE}
}

// 使用对比学习算法，预测深度学习训练作业在模型并行模式下的资源使用，并给出最优的设备使用结果（同构资源）
@inproceedings{lan2021accelerated,
  title={Accelerated Device Placement Optimization with Contrastive Learning},
  author={Lan, Hao and Chen, Li and Li, Baochun},
  booktitle={50th International Conference on Parallel Processing},
  pages={1--10},
  year={2021}
}

// Pesto使用算子粒度的建模，估算算子的运行时间，并考虑在模型并行时的算子放置与调度结果
@inproceedings{hafeez2021towards,
  title={Towards optimal placement and scheduling of DNN operations with Pesto},
  author={Hafeez, Ubaid Ullah and Sun, Xiao and Gandhi, Anshul and Liu, Zhenhua},
  booktitle={Proceedings of the 22nd International Middleware Conference},
  pages={39--51},
  year={2021}
}

// 在云服务之上，如果通过算子预测整个模型的一次运行时间
@inproceedings{hafeez2020empirical,
  title={Empirical Analysis and Modeling of Compute Times of CNN Operations on AWS Cloud},
  author={Hafeez, Ubaid Ullah and Gandhi, Anshul},
  booktitle={2020 IEEE International Symposium on Workload Characterization (IISWC)},
  pages={181--192},
  year={2020},
  organization={IEEE}
}

//机制：nn-Meter将深度学习模型及其算子进行细粒度的划分，能够自动将算子划分为需要的运算单元(由多个算子融合而来)，同时通过数据采样（包含算子的输入数据量和参数维度）便于精准估算算子的运行时间，能够达到接近90%的准确度。NN-meter的局限性在于其只能支持离线融合计算，同时一般算子独占异构资源（边缘环境下有其合理性） ；在可用资源动态变化和算子并发执行下（共享异构资源）的场景还需要扩展，其算子可以预测的对象也仅限于同构资源上的CNN算子，同时，数据采样所需要的时间也较长（1.4-2.5天）。
@inproceedings{zhang2021nn,
  title={nn-Meter: towards accurate latency prediction of deep-learning model inference on diverse edge devices},
  author={Zhang, Li Lyna and Han, Shihao and Wei, Jianyu and Zheng, Ningxin and Cao, Ting and Yang, Yuqing and Liu, Yunxin},
  booktitle={Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services},
  pages={81--93},
  year={2021}
}


# 存在问题

目前DL训练作业的配置推荐，存在以下局限性：
1. 只能针对数据并行场景建模资源使用情况，对模型并行几乎没有支撑；
2. 完成时间的预测一般针对DL训练作业只能使用同构资源。
3. 模型并行的设备放置过程，也只能使用同构资源。

# 设计方案

面向一个DL训练作业的模型并行场景，同时推荐不同的资源型号和数量：

1. 构造DL训练作业的划分方法，不同划分子作业中存在不同的算子，其具有不同的运行时间，和在异构资源上不同的加速情况；
2. 构造自优化搜索算法，对每部分算子分别建模，寻找其最优的GPU型号，以及需要的整体数量；
3. 实验对比与一般只推荐同构资源的工作，有完成时间和推荐成本方面的提升。
