# Titile

Optimus: An Efficient Dynamic Resource Scheduler for Deep
Learning Clusters

## Citing

Peng, Y , et al. "Optimus: An Efficient Dynamic Resource Scheduler for Deep Learning Clusters." (2018).

## Brief introduction

本篇是论文作为继SLAQ之后的ML动态资源调整优化，针对深度学习在参数服务器架构下的调度优化。
针对当前Borg等调度器的静态资源分配和当前调度器不支持Depp Learning负载的问题，通过对DL算法
进行粗粒度建模，来实现资源的动态调整，同时限制资源迁移开销，并提供一定的检查点功能来保障可用性

## Key Methology

1. 将深度学习的模型训练过程的粒度定义为迭代、收敛和和参数服务器三种基础元素；
2. 学习DL的收敛曲线，进行归一化处理，构建多项式反应不同DL应用的变化曲线，用于预测下一阶段的训练质量；
3. 构建资源加速模型，考虑计算和通信开销，给出一个训练步骤的估计时间，也是多项式；
4. 根据模型构建训练速度函数，并对函数进行拟合操作；
5. 在作业任务部署时，首先进行资源分配，资源分配的的目标是优化最小运行时间，每个作业的运行时间通过上述两个多项式来表达；
最终作为一个非线性整数规划问题进行求解，它不是凸优化问题，该文章通过启发式规则进行求解；
6. 在任务放置期间，通过任务和机器资源的重排序进行规划，最终限制数据的跨主机迁移；
7. 在系统实现角度，能够通过简单的资源监控（机器上task的收敛速度小于平均值），来判断满节点；
8. 参数服务器的负载均衡：最小化任意两个参数服务器之间的方差；最小化参数服务器之间的更新开销；


## Data sets

均是开源数据集：ResNext-110，ResNet-50，Inception-BN，KAGGLE等；


## Experimental Design

1. 7台CPU主机；6台GPU主机；1GBE相连；basedline：DRF,Tetris,Kubernetes’ default scheduler
2. 工作负载随机到达；
3. 比较与baseline的CPU利用率（参数服务器与裸机），比较当前运行的任务数；
4. 集群整体角度：JCT和MakeSpan；以及他们预测失败的情况（收敛值和训练速度）；
5. 对比不同工作负载(任务到来时间：泊松分布，google数据集及随机到达)和训练模型下的敏感度（鲁棒性）；

## Conclusion And Future Work

当前较为明显的问题：
1. 约束表达和单维资源约束的问题：没有考虑影响较大的GPU调度和内存管理的问题，这对DL影响很大；其他静态调度器的放置约束也未考虑；
2. 没有考虑生产环境混合调度的这一场景，DL任务独占机器，在真实环境下可操作性差；
3. 收敛估计的预测未必准确性很高，当前也存在若干错误，每个参数都要调整，整数规划启发式规则未必合理;

解决途径：
1. 首先考虑GPU和内存对调度的影响；
2. 通过学习的算法（回归方法等）自动拟合更为准确的训练收敛和速度；
3. 不用整数非线性规划，采用其他更容易理解的方法。
